{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-25T12:44:59.813043Z",
     "start_time": "2021-02-25T12:44:50.640470Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in c:\\users\\dongh\\anaconda3\\lib\\site-packages (4.3.3)\n",
      "Requirement already satisfied: requests in c:\\users\\dongh\\anaconda3\\lib\\site-packages (from transformers) (2.24.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\dongh\\anaconda3\\lib\\site-packages (from transformers) (3.0.12)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\dongh\\anaconda3\\lib\\site-packages (from transformers) (1.19.2)\n",
      "Requirement already satisfied: packaging in c:\\users\\dongh\\anaconda3\\lib\\site-packages (from transformers) (20.4)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\dongh\\anaconda3\\lib\\site-packages (from transformers) (4.50.2)\n",
      "Requirement already satisfied: tokenizers<0.11,>=0.10.1 in c:\\users\\dongh\\anaconda3\\lib\\site-packages (from transformers) (0.10.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\dongh\\anaconda3\\lib\\site-packages (from transformers) (2020.10.15)\n",
      "Requirement already satisfied: sacremoses in c:\\users\\dongh\\anaconda3\\lib\\site-packages (from transformers) (0.0.43)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\dongh\\anaconda3\\lib\\site-packages (from requests->transformers) (2020.6.20)\n",
      "Requirement already satisfied: idna<3,>=2.5 in c:\\users\\dongh\\anaconda3\\lib\\site-packages (from requests->transformers) (2.10)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in c:\\users\\dongh\\anaconda3\\lib\\site-packages (from requests->transformers) (1.25.11)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in c:\\users\\dongh\\anaconda3\\lib\\site-packages (from requests->transformers) (3.0.4)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in c:\\users\\dongh\\anaconda3\\lib\\site-packages (from packaging->transformers) (2.4.7)\n",
      "Requirement already satisfied: six in c:\\users\\dongh\\anaconda3\\lib\\site-packages (from packaging->transformers) (1.15.0)\n",
      "Requirement already satisfied: joblib in c:\\users\\dongh\\anaconda3\\lib\\site-packages (from sacremoses->transformers) (0.17.0)\n",
      "Requirement already satisfied: click in c:\\users\\dongh\\anaconda3\\lib\\site-packages (from sacremoses->transformers) (7.1.2)\n",
      "Requirement already satisfied: wget in c:\\users\\dongh\\anaconda3\\lib\\site-packages (3.2)\n",
      "Looking in links: https://download.pytorch.org/whl/torch_stable.html\n",
      "Requirement already satisfied: torch===1.5.0 in c:\\users\\dongh\\anaconda3\\lib\\site-packages (1.5.0)\n",
      "Collecting torchvision===0.6.0\n",
      "  Using cached https://download.pytorch.org/whl/cu102/torchvision-0.6.0-cp38-cp38-win_amd64.whl (1.2 MB)\n",
      "Requirement already satisfied: numpy in c:\\users\\dongh\\anaconda3\\lib\\site-packages (from torch===1.5.0) (1.19.2)\n",
      "Requirement already satisfied: future in c:\\users\\dongh\\anaconda3\\lib\\site-packages (from torch===1.5.0) (0.18.2)\n",
      "Requirement already satisfied: pillow>=4.1.1 in c:\\users\\dongh\\anaconda3\\lib\\site-packages (from torchvision===0.6.0) (8.0.1)\n",
      "Installing collected packages: torchvision\n",
      "  Attempting uninstall: torchvision\n",
      "    Found existing installation: torchvision 0.8.2\n",
      "    Uninstalling torchvision-0.8.2:\n",
      "      Successfully uninstalled torchvision-0.8.2\n",
      "Successfully installed torchvision-0.6.0\n"
     ]
    }
   ],
   "source": [
    "# HuggingFace transformers 설치 및 NSMC 데이터셋 다운로드\n",
    "!pip install transformers\n",
    "!pip install wget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-25T12:45:17.386456Z",
     "start_time": "2021-02-25T12:44:59.815043Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in links: https://download.pytorch.org/whl/torch_stable.html\n",
      "Collecting torch===1.7.1\n",
      "  Using cached torch-1.7.1-cp38-cp38-win_amd64.whl (184.0 MB)\n",
      "Collecting torchvision===0.8.2\n",
      "  Using cached https://download.pytorch.org/whl/cu102/torchvision-0.8.2-cp38-cp38-win_amd64.whl (1.5 MB)\n",
      "Requirement already satisfied: torchaudio===0.7.2 in c:\\users\\dongh\\anaconda3\\lib\\site-packages (0.7.2)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\dongh\\anaconda3\\lib\\site-packages (from torch===1.7.1) (3.7.4.3)\n",
      "Requirement already satisfied: numpy in c:\\users\\dongh\\anaconda3\\lib\\site-packages (from torch===1.7.1) (1.19.2)\n",
      "Requirement already satisfied: pillow>=4.1.1 in c:\\users\\dongh\\anaconda3\\lib\\site-packages (from torchvision===0.8.2) (8.0.1)\n",
      "Installing collected packages: torch, torchvision\n",
      "  Attempting uninstall: torch\n",
      "    Found existing installation: torch 1.5.0\n",
      "    Uninstalling torch-1.5.0:\n",
      "      Successfully uninstalled torch-1.5.0\n",
      "  Attempting uninstall: torchvision\n",
      "    Found existing installation: torchvision 0.6.0\n",
      "    Uninstalling torchvision-0.6.0:\n",
      "      Successfully uninstalled torchvision-0.6.0\n",
      "Successfully installed torch-1.7.1 torchvision-0.8.2\n"
     ]
    }
   ],
   "source": [
    "#!pip install torch==1.7.0\n",
    "!pip install torch===1.7.1 torchvision===0.8.2 torchaudio===0.7.2 -f https://download.pytorch.org/whl/torch_stable.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-25T12:45:17.401955Z",
     "start_time": "2021-02-25T12:45:17.388458Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from transformers import AutoTokenizer, ElectraForSequenceClassification, AdamW\n",
    "from tqdm.notebook import tqdm\n",
    "import gc\n",
    "from sklearn.model_selection import KFold\n",
    "import wget\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-25T12:45:27.620778Z",
     "start_time": "2021-02-25T12:45:17.403456Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100% [..........................................................................] 9183137 / 9183137"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Preprocessing_review_pos_neg (2).csv'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wget.download('https://raw.githubusercontent.com/e9t/nsmc/master/ratings_test.txt')\n",
    "wget.download('https://raw.githubusercontent.com/e9t/nsmc/master/ratings_train.txt')\n",
    "wget.download('https://raw.githubusercontent.com/donghyun-daniel/4_party_project/master/Review_crawler/csv_output/Preprocessing_review_pos_neg.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-25T12:45:27.636279Z",
     "start_time": "2021-02-25T12:45:27.622780Z"
    }
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-25T12:45:27.651779Z",
     "start_time": "2021-02-25T12:45:27.637780Z"
    }
   },
   "outputs": [],
   "source": [
    "class NSMCDataset(Dataset):\n",
    "    def __init__(self, csv_file):\n",
    "        # 일부 값중에 NaN이 있음...\n",
    "        self.dataset = pd.read_csv(csv_file, sep='\\t').dropna(axis=0) \n",
    "        # 중복제거\n",
    "        self.dataset.drop_duplicates(subset=['document'], inplace=True)\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(\"monologg/koelectra-small-v2-discriminator\")\n",
    "\n",
    "        print(self.dataset.describe())\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataset)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.dataset.iloc[idx, 1:3].values\n",
    "        text = row[0]\n",
    "        y = row[1]\n",
    "\n",
    "        inputs = self.tokenizer(\n",
    "            text, \n",
    "            return_tensors='pt',\n",
    "            truncation=True,\n",
    "            max_length=256,\n",
    "            pad_to_max_length=True,\n",
    "            add_special_tokens=True\n",
    "            )\n",
    "\n",
    "        input_ids = inputs['input_ids'][0]\n",
    "        attention_mask = inputs['attention_mask'][0]\n",
    "\n",
    "        return input_ids, attention_mask, y\n",
    "\n",
    "\n",
    "    \n",
    "def data_concat(naverTrainData, naverTestData, hotelData): \n",
    "    #data_concat(\"ratings_train.txt\", \"ratings_test.txt\", \"Preprocessing_review_pos_neg.csv\")\n",
    "    trainRate = 0.5\n",
    "    \n",
    "    data1 = pd.read_table(naverTrainData)\n",
    "    data2 = pd.read_table(naverTestData)\n",
    "    data3 = pd.read_csv(hotelData)\n",
    "    \n",
    "    data3 = data3.drop(['len_text'], axis=1)\n",
    "    data3['id'] = 1\n",
    "    data3 = data3[['id', 'Text', 'Label']]\n",
    "    data3.columns = ['id','document','label']\n",
    "    data3 = data3.iloc[np.random.permutation(data3.index)].reset_index(drop=True)\n",
    "    \n",
    "    data3Train = data3.sample(frac = trainRate, random_state=2000)\n",
    "    data3Test = data3.drop(data3Train.index)\n",
    "    \n",
    "    trainData = pd.concat([data1, data3Train], ignore_index=True)\n",
    "    testData = pd.concat([data2, data3Test], ignore_index=True)\n",
    "    \n",
    "    trainData.to_csv('sampleTrain.txt', sep = '\\t', index = False)\n",
    "    testData.to_csv('sampleTest.txt', sep = '\\t', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-25T12:45:28.798779Z",
     "start_time": "2021-02-25T12:45:27.654282Z"
    }
   },
   "outputs": [],
   "source": [
    "data_concat(\"ratings_train.txt\", \"ratings_test.txt\", \"Preprocessing_review_pos_neg.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-25T12:45:36.791508Z",
     "start_time": "2021-02-25T12:45:28.800779Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 id          label\n",
      "count  1.964880e+05  196488.000000\n",
      "mean   5.043539e+06       0.499802\n",
      "std    3.885084e+06       0.500001\n",
      "min    1.000000e+00       0.000000\n",
      "25%    1.000000e+00       0.000000\n",
      "50%    5.836175e+06       0.000000\n",
      "75%    8.768916e+06       1.000000\n",
      "max    1.027815e+07       1.000000\n",
      "                 id         label\n",
      "count  9.950700e+04  99507.000000\n",
      "mean   3.335992e+06      0.505733\n",
      "std    3.957364e+06      0.499970\n",
      "min    1.000000e+00      0.000000\n",
      "25%    1.000000e+00      0.000000\n",
      "50%    1.000000e+00      1.000000\n",
      "75%    7.526732e+06      1.000000\n",
      "max    1.027809e+07      1.000000\n"
     ]
    }
   ],
   "source": [
    "train_dataset = NSMCDataset(\"sampleTrain.txt\")\n",
    "test_dataset = NSMCDataset(\"sampleTest.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-25T12:45:38.309717Z",
     "start_time": "2021-02-25T12:45:36.792509Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at monologg/koelectra-small-v2-discriminator were not used when initializing ElectraForSequenceClassification: ['discriminator_predictions.dense.weight', 'discriminator_predictions.dense.bias', 'discriminator_predictions.dense_prediction.weight', 'discriminator_predictions.dense_prediction.bias']\n",
      "- This IS expected if you are initializing ElectraForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ElectraForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of ElectraForSequenceClassification were not initialized from the model checkpoint at monologg/koelectra-small-v2-discriminator and are newly initialized: ['classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.weight', 'classifier.out_proj.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "Torch not compiled with CUDA enabled",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-36-4fcd651fd61d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mElectraForSequenceClassification\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"monologg/koelectra-small-v2-discriminator\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36mto\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    610\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_floating_point\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_blocking\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    611\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 612\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconvert\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    613\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    614\u001b[0m     def register_backward_hook(\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_apply\u001b[1;34m(self, fn)\u001b[0m\n\u001b[0;32m    357\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_apply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    358\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 359\u001b[1;33m             \u001b[0mmodule\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    360\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    361\u001b[0m         \u001b[1;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_apply\u001b[1;34m(self, fn)\u001b[0m\n\u001b[0;32m    357\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_apply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    358\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 359\u001b[1;33m             \u001b[0mmodule\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    360\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    361\u001b[0m         \u001b[1;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_apply\u001b[1;34m(self, fn)\u001b[0m\n\u001b[0;32m    357\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_apply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    358\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 359\u001b[1;33m             \u001b[0mmodule\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    360\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    361\u001b[0m         \u001b[1;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_apply\u001b[1;34m(self, fn)\u001b[0m\n\u001b[0;32m    379\u001b[0m                 \u001b[1;31m# `with torch.no_grad():`\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    380\u001b[0m                 \u001b[1;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 381\u001b[1;33m                     \u001b[0mparam_applied\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    382\u001b[0m                 \u001b[0mshould_use_set_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparam_applied\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    383\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mshould_use_set_data\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36mconvert\u001b[1;34m(t)\u001b[0m\n\u001b[0;32m    608\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mconvert_to_format\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m4\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    609\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_floating_point\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_blocking\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmemory_format\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mconvert_to_format\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 610\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_floating_point\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_blocking\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    611\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    612\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconvert\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\cuda\\__init__.py\u001b[0m in \u001b[0;36m_lazy_init\u001b[1;34m()\u001b[0m\n\u001b[0;32m    164\u001b[0m                 \"Cannot re-initialize CUDA in forked subprocess. \" + msg)\n\u001b[0;32m    165\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'_cuda_getDeviceCount'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 166\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mAssertionError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Torch not compiled with CUDA enabled\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    167\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0m_cudart\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    168\u001b[0m             raise AssertionError(\n",
      "\u001b[1;31mAssertionError\u001b[0m: Torch not compiled with CUDA enabled"
     ]
    }
   ],
   "source": [
    "model = ElectraForSequenceClassification.from_pretrained(\"monologg/koelectra-small-v2-discriminator\").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-25T12:45:38.311718Z",
     "start_time": "2021-02-25T12:42:45.040Z"
    }
   },
   "outputs": [],
   "source": [
    "# 에러나도 그냥 넘어가면 됨\n",
    "model.load_state_dict(torch.load(\"model.pt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-25T12:45:38.312218Z",
     "start_time": "2021-02-25T12:42:45.040Z"
    }
   },
   "outputs": [],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-25T12:45:38.313219Z",
     "start_time": "2021-02-25T12:42:45.041Z"
    }
   },
   "outputs": [],
   "source": [
    "# GPU 메모리 터지는거 방지\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-25T12:45:38.313718Z",
     "start_time": "2021-02-25T12:42:45.043Z"
    }
   },
   "outputs": [],
   "source": [
    "epochs = 3\n",
    "batch_size = 64\n",
    "\n",
    "optimizer = AdamW(model.parameters(), lr=1e-5)\n",
    "\n",
    "# 10 fold cross val\n",
    "kfold = KFold(n_splits=10, shuffle=True)\n",
    "\n",
    "test_loader = DataLoader(test_dataset, batch_size=16, shuffle=True)\n",
    "\n",
    "kfold_losses = []\n",
    "kfold_acc = []\n",
    "\n",
    "\n",
    "for fold, (train_ids, val_ids) in enumerate(kfold.split(train_dataset)):\n",
    "    print('----------------------------------')\n",
    "    print(fold)\n",
    "\n",
    "    train_subsampler = torch.utils.data.SubsetRandomSampler(train_ids)\n",
    "    val_subsampler = torch.utils.data.SubsetRandomSampler(val_ids)\n",
    "    \n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, sampler=train_subsampler)\n",
    "    val_loader = DataLoader(train_dataset, batch_size=batch_size, sampler=val_subsampler)\n",
    "    \n",
    "    losses = []\n",
    "    accuracies = []\n",
    "    \n",
    "    for i in range(epochs):\n",
    "        total_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        batches = 0\n",
    "\n",
    "        model.train()\n",
    "\n",
    "        for input_ids_batch, attention_masks_batch, y_batch in tqdm(train_loader):\n",
    "            optimizer.zero_grad()\n",
    "            y_batch = y_batch.to(device)\n",
    "            y_pred = model(input_ids_batch.to(device), attention_mask=attention_masks_batch.to(device))[0]\n",
    "            loss = F.cross_entropy(y_pred, y_batch)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            total_loss += loss.item()\n",
    "\n",
    "            _, predicted = torch.max(y_pred, 1)\n",
    "            correct += (predicted == y_batch).sum()\n",
    "            total += len(y_batch)\n",
    "\n",
    "            batches += 1\n",
    "            if batches % 100 == 0:\n",
    "                print(\"Batch Loss:\", total_loss, \"Accuracy:\", correct.float() / total)\n",
    "\n",
    "        losses.append(total_loss)\n",
    "        accuracies.append(correct.float() / total)\n",
    "        print(\"Train Loss:\", total_loss, \"Accuracy:\", correct.float() / total)\n",
    "    loss_avg = sum(losses) / len(losses)\n",
    "    acc_avg = sum(accuracies) / len(accuracies)\n",
    "    kfold_losses.append(loss_avg)\n",
    "    kfold_acc.append(acc_avg)\n",
    "    \n",
    "    print('----------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-25T12:45:38.314217Z",
     "start_time": "2021-02-25T12:42:45.043Z"
    }
   },
   "outputs": [],
   "source": [
    "kfold_losses, kfold_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-25T12:45:38.314717Z",
     "start_time": "2021-02-25T12:42:45.044Z"
    }
   },
   "outputs": [],
   "source": [
    "model.eval()\n",
    "\n",
    "test_correct = 0\n",
    "test_total = 0\n",
    "\n",
    "for input_ids_batch, attention_masks_batch, y_batch in tqdm(test_loader):\n",
    "    y_batch = y_batch.to(device)\n",
    "    y_pred = model(input_ids_batch.to(device), attention_mask=attention_masks_batch.to(device))[0]\n",
    "    _, predicted = torch.max(y_pred, 1)\n",
    "    test_correct += (predicted == y_batch).sum()\n",
    "    test_total += len(y_batch)\n",
    "\n",
    "print(\"Accuracy:\", test_correct.float() / test_total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-25T12:45:38.315717Z",
     "start_time": "2021-02-25T12:42:45.045Z"
    }
   },
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), \"model.pt\")\n",
    "\n",
    "## 여기까지"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-25T12:45:38.316217Z",
     "start_time": "2021-02-25T12:42:45.045Z"
    }
   },
   "outputs": [],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-25T12:45:38.316717Z",
     "start_time": "2021-02-25T12:42:45.047Z"
    }
   },
   "outputs": [],
   "source": [
    "_, pre=torch.max(y_pred, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-25T12:45:38.317217Z",
     "start_time": "2021-02-25T12:42:45.048Z"
    }
   },
   "outputs": [],
   "source": [
    "pre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-25T12:45:38.318217Z",
     "start_time": "2021-02-25T12:42:45.048Z"
    }
   },
   "outputs": [],
   "source": [
    "train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-25T12:45:38.318717Z",
     "start_time": "2021-02-25T12:42:45.049Z"
    }
   },
   "outputs": [],
   "source": [
    "train_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-25T12:45:38.319717Z",
     "start_time": "2021-02-25T12:42:45.050Z"
    }
   },
   "outputs": [],
   "source": [
    "input_ids_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-25T12:45:38.320217Z",
     "start_time": "2021-02-25T12:42:45.051Z"
    }
   },
   "outputs": [],
   "source": [
    "attention_masks_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-25T12:45:38.320717Z",
     "start_time": "2021-02-25T12:42:45.052Z"
    }
   },
   "outputs": [],
   "source": [
    "y_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-25T12:45:38.321717Z",
     "start_time": "2021-02-25T12:42:45.053Z"
    }
   },
   "outputs": [],
   "source": [
    "for input_ids_batch, attention_masks_batch, y_batch in tqdm(train_loader):\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-25T12:45:38.322217Z",
     "start_time": "2021-02-25T12:42:45.054Z"
    }
   },
   "outputs": [],
   "source": [
    "input_ids_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-25T12:45:38.323219Z",
     "start_time": "2021-02-25T12:42:45.054Z"
    }
   },
   "outputs": [],
   "source": [
    "attention_masks_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-25T12:45:38.324217Z",
     "start_time": "2021-02-25T12:42:45.055Z"
    }
   },
   "outputs": [],
   "source": [
    "y_batch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 올릴 방법\n",
    "\n",
    "- 어근 치환 ***\n",
    "- k-fold crossval \n",
    "\n",
    "- pretrain 모델 변경 ***\n",
    "\n",
    "- fine tuning\n",
    "// - 데이터 추가 영화, 호텔, 쇼핑 데이터\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-25T12:45:38.325217Z",
     "start_time": "2021-02-25T12:42:45.056Z"
    }
   },
   "outputs": [],
   "source": [
    "data = [1,2,3,4,5,6,7,8,9,10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
